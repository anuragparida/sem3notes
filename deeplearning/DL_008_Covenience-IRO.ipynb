{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b044e3d",
   "metadata": {},
   "source": [
    "# Convenient experimenation with Tensorflow\n",
    "\n",
    "In this notebook we learn about some shortcuts or convenience methods for modelling neuronal networks with tensorflow\n",
    "\n",
    "Get the necessary data files for the next session from https://www.kaggle.com/datasets/zalando-research/fashionmnist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f965a17",
   "metadata": {},
   "source": [
    "## Preparing the Fashion MNIST-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9930901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "#!pip install tensorflow==2.10\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "print(f\"Tesorflow version {tf.__version__}\")\n",
    "\n",
    "#read data with pandas\n",
    "dataTrain = pd.read_csv('data/fashion-mnist_train.csv')\n",
    "dataTest = pd.read_csv('data/fashion-mnist_test.csv')\n",
    "\n",
    "#convert to numpy and initialize variables for training\n",
    "X_train, y_train = dataTrain.iloc[:, 1:].to_numpy(), dataTrain.iloc[:, 0].to_numpy()\n",
    "X_test, y_test = dataTest.iloc[:, 1:].to_numpy(), dataTest.iloc[:, 0].to_numpy()\n",
    "\n",
    "#Define Classnames\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# prepare ground truth as one-hot encoded values\n",
    "y_one_hot = tf.one_hot(y_train,len(class_names))\n",
    "y_one_hot_test = tf.one_hot(y_test,len(class_names))\n",
    "\n",
    "\n",
    "print(\"Fashion Mnist\")\n",
    "print(f\"Training data size: {X_train.shape}\")\n",
    "print(f\"Test data size:     {X_test.shape}\")\n",
    "print(f\"One Hot encoded:    {y_one_hot.shape}\")\n",
    "print(f\"Hardware: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd1b813",
   "metadata": {},
   "source": [
    "# Flatten Layer \n",
    "\n",
    "Not always is the data already in the correct format.\n",
    "So far we always had one-dimensional training samples as a input for NN-Layers. It can also be multidimensional if the next layers support this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba61f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppose we have the original data not in the original form\n",
    "X_train_28x28 = X_train.reshape(-1,28,28)\n",
    "plt.figure(figsize=(1.5, 1.5))\n",
    "plt.imshow(X_train_28x28[0], cmap=\"gray_r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_28x28 = X_test.reshape(-1,28,28)\n",
    "plt.figure(figsize=(1.5, 1.5))\n",
    "plt.imshow(X_test_28x28[0], cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6fc77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))                                                   # the flatten layer\n",
    "model.add(Dense(100, activation=\"sigmoid\", input_shape=(784,)))\n",
    "model.add(Dense(len(class_names), activation=\"softmax\"))\n",
    "model.compile(optimizer='sgd', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "    X_train_28x28,                                                                        # unflattened input\n",
    "    y_one_hot,\n",
    "    epochs=10,\n",
    "    batch_size=100)\n",
    "\n",
    "print(\"Evaluation on Test Data\")\n",
    "print(model.evaluate(X_test_28x28, y_one_hot_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a97d6ba",
   "metadata": {},
   "source": [
    "# Shortcut: Loss Function SparseCategoricalCrossentropy\n",
    "\n",
    "Categorial Crossentroypy is a loss function for one-hot-endoded multinomial labels. We can ommit the step of one hot encoding the labels and let the work to the loss-fuction.\n",
    "\n",
    "$Cost(h_\\theta(x),y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a22b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation=\"sigmoid\", input_shape=(784,)))\n",
    "model.add(Dense(len(class_names), activation=\"softmax\"))\n",
    "model.compile(optimizer='sgd', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) # change to sparse_categorial_crossentropy here\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_one_hot,  # you can dircetly use y_train here\n",
    "    epochs=10,\n",
    "    batch_size=100)\n",
    "\n",
    "print(\"Evaluation on Test Data\")\n",
    "print(model.evaluate(X_test, y_test)) # the different loss has also effect on evaluate .. we must change the expected labels here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563cb2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test[0:2]) # the loss doesnt change the output here, we still need the argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f718a0e5",
   "metadata": {},
   "source": [
    "# Testtrain split integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e041eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation=\"sigmoid\", input_shape=(784,)))\n",
    "model.add(Dense(len(class_names), activation=\"softmax\"))\n",
    "model.compile(optimizer='sgd', loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,  # used instead of y_one_hot\n",
    "    epochs=10,\n",
    "    batch_size=100,\n",
    "    validation_split=0.3\n",
    "    #validation_data=(X_test, y_test)\n",
    ")\n",
    "\n",
    "print(\"Evaluation on Test Data\")\n",
    "print(model.evaluate(X_test, y_test)) # the different loss has also effect on evaluate .. we must change the expected labels here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e72bac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d6924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8083e20a",
   "metadata": {},
   "source": [
    "# Creating Sequentical models with the constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a3c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "      Dense(100, activation='sigmoid'),\n",
    "      Dense(10, activation=\"softmax\")\n",
    "      ])\n",
    "model.compile(optimizer='sgd', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_one_hot,\n",
    "    epochs=10,\n",
    "    batch_size=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
