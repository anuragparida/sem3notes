{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b044e3d",
   "metadata": {},
   "source": [
    "# Saving and loading\n",
    "\n",
    "Get the necessary files for the next session from https://www.kaggle.com/datasets/zalando-research/fashionmnist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f965a17",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9930901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "#!pip install tensorflow==2.10\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "print(\"Tesorflow version {tf.__version__}\")\n",
    "\n",
    "#read data with pandas\n",
    "dataTrain = pd.read_csv('data/fashion-mnist_train.csv')\n",
    "dataTest = pd.read_csv('data/fashion-mnist_test.csv')\n",
    "#convert to numpy and initialize variables for training\n",
    "X_train, y_train = dataTrain.iloc[:, 1:].to_numpy(), dataTrain.iloc[:, 0].to_numpy()\n",
    "X_test, y_test = dataTest.iloc[:, 1:].to_numpy(), dataTest.iloc[:, 0].to_numpy()\n",
    "\n",
    "#Define Classnames\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# prepare ground truth as one-hot encoded values\n",
    "y_one_hot = tf.one_hot(y_train,len(class_names))\n",
    "y_one_hot_test = tf.one_hot(y_test,len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d511a7",
   "metadata": {},
   "source": [
    "# Now make the model overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61bc05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.experimental import SGD\n",
    "model = Sequential([\n",
    "      Dense(512, activation='relu'),\n",
    "      Dense(512, activation='relu'),\n",
    "      Dense(10, activation=\"softmax\")\n",
    "      ])\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "model.fit(\n",
    "    X_test,\n",
    "    y_one_hot_test,\n",
    "    epochs=10,\n",
    "    batch_size=100)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1473d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation on Training Data\")\n",
    "print(model.evaluate(X_train[0:10000], y_one_hot[0:10000], batch_size=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ae7665",
   "metadata": {},
   "source": [
    "# Saving & Loading just the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09c3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following craete a savedirectory if not yet available\n",
    "!mkdir testmodel\n",
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383fc7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"testmodel/model1.h5\",  save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir testmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c70e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate the network\n",
    "model2 = Sequential([\n",
    "      Dense(512, activation='relu'),\n",
    "      Dense(512, activation='relu'),\n",
    "      Dense(10, activation=\"softmax\")\n",
    "      ])\n",
    "model2.load_weights(\"testmodel/model1\")\n",
    "model2.compile(optimizer=SGD(learning_rate=0.001), loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb92f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation on Training Data\")\n",
    "print(model2.evaluate(X_train[0:10000], y_one_hot[0:10000], batch_size=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5f95d4",
   "metadata": {},
   "source": [
    "# Saving & Loading the complete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0193f534",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"testmodel/model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e866c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model3 = keras.models.load_model(\"testmodel/model2\")\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation on Training Data\")\n",
    "print(model3.evaluate(X_train[0:10000], y_one_hot[0:10000], batch_size=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d018f10",
   "metadata": {},
   "source": [
    "# Saving continuously during training\n",
    "\n",
    "ModelCheckpoints help to regularily save the model during training. This is good on cloud environments like google colab, when your model could be unexpectedly stopped to not loose already gained progress.\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab7b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "      Dense(512, activation='relu'),\n",
    "      Dense(512, activation='relu'),\n",
    "      Dense(10, activation=\"softmax\")\n",
    "      ])\n",
    "model.compile(\n",
    "    optimizer=SGD(learning_rate=0.001), \n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint;\n",
    "cp_callback = ModelCheckpoint(filepath=\"testmodel/training\",\n",
    "                              save_weights_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=100,\n",
    "    callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c406332",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.load_weights(\"testmodel/training\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
